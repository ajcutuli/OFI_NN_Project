{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data:\n",
    "# 1. read the text file line by line;\n",
    "# 2. format the data in DataFrame.\n",
    "\n",
    "def read_data(path):\n",
    "    data_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            d_str = line.split()\n",
    "            d_tem = [float(d) for d in d_str]\n",
    "            data_list.append(d_tem)\n",
    "    data = pd.DataFrame(data_list)\n",
    "    return data.T\n",
    "\n",
    "# ready data for training:\n",
    "# 1. sample_size=100: the most 100 recent updates\n",
    "# 2. feature_num=40: 40 features per time stamp\n",
    "# 3. target_num=5: relative changes for the next 1,2,3,5 and 10 events(5 in total)\n",
    "def get_model_data(data, sample_size=100, feature_num=40, target_num=5):\n",
    "    data = data.values\n",
    "    shape = data.shape\n",
    "    X = np.zeros((shape[0]-sample_size, sample_size, feature_num))\n",
    "    Y = np.zeros(shape=(shape[0]-sample_size, target_num))\n",
    "    for i in range(shape[0]-sample_size):\n",
    "        X[i] = data[i:i+sample_size,0:feature_num]# take the first 40 columns as features\n",
    "        Y[i] = data[i+sample_size-1,-target_num:]# take the last 5 columns as labels\n",
    "    X = X.reshape(X.shape[0], sample_size, feature_num, 1)# add the 4th dimension: 1 channel\n",
    "    \n",
    "    # \"Benchmark dataset for mid-price forecasting of limit order book data with machine learning\"\n",
    "    # labels 1: equal to or greater than 0.002\n",
    "    # labels 2: -0.00199 to 0.00199\n",
    "    # labels 3: smaller or equal to -0.002\n",
    "    # Y=Y-1 relabels as 0,1,2\n",
    "    Y = Y-1\n",
    "    return X,Y\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'Train_Dst_NoAuction_ZScore_CF_9.txt'\n",
    "data = read_data(data_path)\n",
    "train_X, train_Y = get_model_data(data)\n",
    "train_Y = train_Y.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362300, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362300, 100, 40, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 40, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 100, 20, 16)  48          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 100, 20, 16)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 100, 20, 16)  1040        ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 100, 20, 16)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 100, 20, 16)  1040        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 100, 20, 16)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 100, 10, 16)  528         ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 100, 10, 16)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 100, 10, 16)  1040        ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 100, 10, 16)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 100, 10, 16)  1040        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 100, 10, 16)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 100, 1, 16)   2576        ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 100, 1, 16)   0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 100, 1, 16)   1040        ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 100, 1, 16)   0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 100, 1, 16)   1040        ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 100, 1, 16)   0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 100, 1, 32)   544         ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 100, 1, 32)   544         ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 100, 1, 32)   0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 100, 1, 16)   0           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 100, 1, 32)   3104        ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 100, 1, 32)   5152        ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 100, 1, 32)   544         ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 100, 1, 32)   0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 100, 1, 96)   0           ['leaky_re_lu_10[0][0]',         \n",
      "                                                                  'leaky_re_lu_12[0][0]',         \n",
      "                                                                  'leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 100, 96)      0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           41216       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            195         ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 60,691\n",
      "Trainable params: 60,691\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the size of a single input is (100,40)\n",
    "input_tensor = Input(shape=(100,40,1))\n",
    "\n",
    "# convolutional filter is (1,2) with stride of (1,2)\n",
    "layer_x = layers.Conv2D(16, (1,2), strides=(1,2))(input_tensor)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "layer_x = layers.Conv2D(16, (1,2), strides=(1,2))(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "layer_x = layers.Conv2D(16, (1,10))(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "# Inception Module\n",
    "tower_1 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\n",
    "tower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = layers.Conv2D(32, (3,1), padding='same')(tower_1)\n",
    "tower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n",
    "\n",
    "tower_2 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\n",
    "tower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = layers.Conv2D(32, (5,1), padding='same')(tower_2)\n",
    "tower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)  \n",
    "\n",
    "tower_3 = layers.MaxPooling2D((3,1), padding='same', strides=(1,1))(layer_x)\n",
    "tower_3 = layers.Conv2D(32, (1,1), padding='same')(tower_3)\n",
    "tower_3 = layers.LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "layer_x = layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "\n",
    "# concatenate features of tower_1, tower_2, tower_3\n",
    "layer_x = layers.Reshape((100,96))(layer_x)\n",
    "\n",
    "# 64 LSTM units\n",
    "layer_x = LSTM(64)(layer_x)\n",
    "# The last output layer uses a softmax activation function\n",
    "output = layers.Dense(3, activation='softmax')(layer_x)\n",
    "model = Model(input_tensor, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(train_Y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajcutuli/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.01, epsilon=1)# learning rate and epsilon are the same as paper DeepLOB\n",
    "y = to_categorical(train_Y[:,0])# y is the next event's mid price (k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.fit of <keras.engine.functional.Functional object at 0x7f94dc686a00>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajcutuli/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11322/11322 [==============================] - 2374s 209ms/step - loss: 0.8946 - accuracy: 0.6386\n",
      "Epoch 2/100\n",
      "11322/11322 [==============================] - 1905s 168ms/step - loss: 0.7718 - accuracy: 0.6737\n",
      "Epoch 3/100\n",
      "11322/11322 [==============================] - 2187s 193ms/step - loss: 0.6991 - accuracy: 0.6973\n",
      "Epoch 4/100\n",
      "11322/11322 [==============================] - 2159s 191ms/step - loss: 0.6666 - accuracy: 0.7088\n",
      "Epoch 5/100\n",
      "11322/11322 [==============================] - 2331s 206ms/step - loss: 0.6574 - accuracy: 0.7151\n",
      "Epoch 6/100\n",
      "  836/11322 [=>............................] - ETA: 37:19 - loss: 0.6481 - accuracy: 0.7321"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(train_X, y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.to_csv('FI2010_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'Test_Dst_NoAuction_ZScore_CF_9.txt'\n",
    "test_data = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y = get_model_data(test_data)\n",
    "test_Y = test_Y.astype(int)\n",
    "test_y = to_categorical(test_Y[:,0])\n",
    "\n",
    "model.evaluate(test_X, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
